---
layout: archive
title: ""
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* Ph.D. in Computer Science, Emory University, Sep 2019 – Dec 2024 
* M.S. in Physics, College of William & Mary, Sep 2017 – May 2019
* B.S. in Physics, University of Science and Technology of China, Sep 2013 – Jun 2017

Research Interests
======
* Graph representation learning
* Spatiotemporal analysis
* Large language models
* Anomaly detection
* Large-scale machine learning algorithm design

Skills
======
* Programming: Python, C/C++, MATLAB, Java, Shell
* Deep learning frameworks: Pytorch, Tensorflow, Transformers
* Large-scale tools: Deepspeed, Spark
* Over 6 years of experience in building large-scale machine learning pipelines

Work Experience
======
* **Machine Learning Engineer Intern**, Pinterest (Remote), US – May 2024 – Present  
  * Improved recall and precision performance in a two-tower recommendation system through neural retrieval algorithms.
  * Evaluated models’ performance on approximated nearest neighbor search using hierarchical navigable small world algorithms.

* **Applied Scientist Intern**, Amazon Alexa AI, Bellevue, WA, US – Sep 2023 – Dec 2023  
  * Addressed positional bias within the context window for large language models, enhancing their capability to interpret long input contexts.
  * Evaluated models’ performance on downstream Amazon recommendation tasks.

* **Research Intern**, TikTok Applied Machine Learning (AML), San Jose, CA, US – May 2023 – Aug 2023  
  * Managed balance between specialized and general skills in large language models like Llama and Vicuna by implementing fine-tuning and data strategies.
  * Investigated model size and continual learning impacts to enhance language model generation quality for downstream business applications.

* **Quantitative Research Intern**, ZHUOSHI Quant Trading Investment, Beijing, China – May 2019 – Aug 2019  
  * Developed a gradient boosting regression tree (GBRT) model for predicting asset movements with up to 1 billion CNY market capital.
  * Achieved an annual average PnL of over 45% and a Sharpe ratio of 11.3 in the Chinese equity market backtest.

Research Experience
======
* **Improving Generalization and Robustness of GNN Models via Curriculum Learning**, Emory University – May 2022 – Sep 2022  
  * Proposed a curriculum learning strategy for handling data dependencies in graph-structured data.
  * Achieved best node classification performance on 20 out of 21 benchmark real-world datasets.

* **Unsupervised Detection of Group Anomalies in Graphs**, Emory University – Aug 2021 – May 2022  
  * Developed a graph autoencoder framework for detecting subgraph anomalies in an unsupervised manner.
  * Achieved best detection performance compared to state-of-the-art models on multiple tasks, including fraud detection.

* **Expressive Representation Learning on Spatial Networks**, Emory University – Sep 2020 – May 2021  
  * Proposed a third-order GNN model for spatial and network information interaction.
  * Outperformed state-of-the-art models by over 38% on real-world tasks like drug discovery and neuroscience.

Selected Publications
======
* Zheng Zhang, Allen Zhang, Ruth Nelson, Giorgio Ascoli, Liang Zhao. **Representation Learning of Geometric Trees**, 30th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2024), Research Track, accepted, 2024.
* Zheng Zhang, Sirui Li, Jingcheng Zhou, Junxiang Wang, Abhinav Angirekula, Allen Zhang, Liang Zhao. **Non-Euclidean Spatial Graph Neural Network**, SIAM Conference on Data Mining (SDM 2024), accepted, 2024.
* Zheng Zhang, and Liang Zhao. **Self-Similar Graph Neural Network for Hierarchical Graph Learning**, SIAM Conference on Data Mining (SDM 2024), accepted, 2024.
* Zheng Zhang, Junxiang Wang and Liang Zhao. **Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First**, The 37th Conference on Neural Information Processing Systems (NeurIPS 2023), full paper, 2023.
* Zheng Zhang and Liang Zhao. **Unsupervised Deep Subgraph Anomaly Detection**, The IEEE International Conference on Data Mining (ICDM 2022), full paper, [Best Paper Award].

Awards
======
* **NeurIPS Scholar Award**, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
* **Best Paper Award**, 22nd International Conference on Data Mining (ICDM 2022)
* **Student Travel Award**, 22nd International Conference on Data Mining (ICDM 2022)
* **First Prize**, National Physics Olympiads of China, 2012
* **First Prize**, National Informatics Olympiads of China, 2010

